{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e9a5ac-d438-40f5-9596-a18ec083a014",
   "metadata": {},
   "source": [
    "# @part1: OCR 모델 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5629dfc-8faa-47d4-b8fa-a468e2d76095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Download command: `omz_downloader --name horizontal-text-detection-0001,text-recognition-resnet-fc --output_dir model --cache_dir model --precision FP16  --num_attempts 5`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Downloading horizontal-text-detection-0001, text-recognition-resnet-fc..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading horizontal-text-detection-0001 ||################\n",
      "\n",
      "========== Retrieving model/intel/horizontal-text-detection-0001/FP16/horizontal-text-detection-0001.xml from the cache\n",
      "\n",
      "========== Retrieving model/intel/horizontal-text-detection-0001/FP16/horizontal-text-detection-0001.bin from the cache\n",
      "\n",
      "################|| Downloading text-recognition-resnet-fc ||################\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/__init__.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/builder.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/model.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/weight_init.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/registry.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/heads/__init__.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/heads/builder.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/heads/fc_head.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/heads/registry.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/__init__.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/builder.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/registry.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/body.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/component.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/sequences/__init__.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/sequences/builder.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/sequences/registry.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/__init__.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/builder.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/decoders/__init__.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/decoders/builder.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/decoders/registry.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/decoders/bricks/__init__.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/decoders/bricks/bricks.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/decoders/bricks/builder.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/decoders/bricks/registry.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/encoders/__init__.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/encoders/builder.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/encoders/backbones/__init__.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/encoders/backbones/builder.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/encoders/backbones/registry.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/encoders/backbones/resnet.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/encoders/enhance_modules/__init__.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/encoders/enhance_modules/builder.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/encoders/enhance_modules/registry.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/utils/__init__.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/utils/builder.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/utils/conv_module.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/utils/fc_module.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/utils/norm.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/models/utils/registry.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/utils/__init__.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/utils/common.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/utils/registry.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/utils/config.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/configs/resnet_fc.py from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/ckpt/resnet_fc.pth from the cache\n",
      "\n",
      "========== Retrieving model/public/text-recognition-resnet-fc/vedastr/addict-2.4.0-py3-none-any.whl from the cache\n",
      "\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/models/heads/__init__.py\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/models/bodies/__init__.py\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/models/bodies/sequences/__init__.py\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/models/bodies/component.py\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/decoders/__init__.py\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/decoders/bricks/__init__.py\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/encoders/backbones/__init__.py\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/encoders/enhance_modules/__init__.py\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/models/utils/__init__.py\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/utils/__init__.py\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/utils/config.py\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/utils/config.py\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/utils/config.py\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/utils/config.py\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/utils/config.py\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/encoders/backbones/resnet.py\n",
      "========== Replacing text in model/public/text-recognition-resnet-fc/vedastr/models/bodies/feature_extractors/encoders/backbones/resnet.py\n",
      "========== Unpacking model/public/text-recognition-resnet-fc/vedastr/addict-2.4.0-py3-none-any.whl\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Finished downloading horizontal-text-detection-0001, text-recognition-resnet-fc."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import openvino as ov\n",
    "from IPython.display import Markdown, display\n",
    "from PIL import Image\n",
    "\n",
    "# Fetch `notebook_utils` module\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\n",
    "    url='https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/utils/notebook_utils.py',\n",
    "    filename='notebook_utils.py'\n",
    ")\n",
    "from notebook_utils import load_image\n",
    "\n",
    "\n",
    "core = ov.Core()\n",
    "\n",
    "model_dir = Path(\"model\")\n",
    "precision = \"FP16\"\n",
    "detection_model = \"horizontal-text-detection-0001\"\n",
    "recognition_model = \"text-recognition-resnet-fc\"\n",
    "\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "download_command = f\"omz_downloader --name {detection_model},{recognition_model} --output_dir {model_dir} --cache_dir {model_dir} --precision {precision}  --num_attempts 5\"\n",
    "display(Markdown(f\"Download command: `{download_command}`\"))\n",
    "display(Markdown(f\"Downloading {detection_model}, {recognition_model}...\"))\n",
    "!$download_command\n",
    "display(Markdown(f\"Finished downloading {detection_model}, {recognition_model}.\"))\n",
    "\n",
    "detection_model_path = (model_dir / \"intel/horizontal-text-detection-0001\" / precision / detection_model).with_suffix(\".xml\")\n",
    "recognition_model_path = (model_dir / \"public/text-recognition-resnet-fc\" / precision / recognition_model).with_suffix(\".xml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f92698-f14a-47c9-bc5e-885b73d03ac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Convert command: `omz_converter --name text-recognition-resnet-fc --precisions FP16 --download_dir model --output_dir model`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Converting text-recognition-resnet-fc..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Converting text-recognition-resnet-fc to ONNX\n",
      "Conversion to ONNX command: /home/hong/openvino/.openvino_env/bin/python3 -- /home/hong/openvino/.openvino_env/lib/python3.10/site-packages/openvino/model_zoo/internal_scripts/pytorch_to_onnx.py --model-path=/home/hong/openvino/.openvino_env/lib/python3.10/site-packages/openvino/model_zoo/models/public/text-recognition-resnet-fc --model-path=model/public/text-recognition-resnet-fc --model-name=get_model --import-module=model '--model-param=file_config=r\"model/public/text-recognition-resnet-fc/vedastr/configs/resnet_fc.py\"' '--model-param=weights=r\"model/public/text-recognition-resnet-fc/vedastr/ckpt/resnet_fc.pth\"' --input-shape=1,1,32,100 --input-names=input --output-names=output --output-file=model/public/text-recognition-resnet-fc/resnet_fc.onnx\n",
      "\n",
      "ONNX check passed successfully.\n",
      "\n",
      "========== Converting text-recognition-resnet-fc to IR (FP16)\n",
      "Conversion command: /home/hong/openvino/.openvino_env/bin/python3 -- /home/hong/openvino/.openvino_env/bin/mo --framework=onnx --output_dir=model/public/text-recognition-resnet-fc/FP16 --model_name=text-recognition-resnet-fc --input=input '--mean_values=input[127.5]' '--scale_values=input[127.5]' --output=output --input_model=model/public/text-recognition-resnet-fc/resnet_fc.onnx '--layout=input(NCHW)' '--input_shape=[1, 1, 32, 100]' --compress_to_fp16=True\n",
      "\n",
      "[ INFO ] Generated IR will be compressed to FP16. If you get lower accuracy, please consider disabling compression explicitly by adding argument --compress_to_fp16=False.\n",
      "Find more information about compression to FP16 at https://docs.openvino.ai/2023.0/openvino_docs_MO_DG_FP16_Compression.html\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai/2023.0/openvino_2_0_transition_guide.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/hong/mini_pjt_1219/OpenVINO_mini_project/model/public/text-recognition-resnet-fc/FP16/text-recognition-resnet-fc.xml\n",
      "[ SUCCESS ] BIN file: /home/hong/mini_pjt_1219/OpenVINO_mini_project/model/public/text-recognition-resnet-fc/FP16/text-recognition-resnet-fc.bin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "convert_command = f\"omz_converter --name {recognition_model} --precisions {precision} --download_dir {model_dir} --output_dir {model_dir}\"\n",
    "display(Markdown(f\"Convert command: `{convert_command}`\"))\n",
    "display(Markdown(f\"Converting {recognition_model}...\"))\n",
    "! $convert_command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b37a80a-d992-4f67-a593-8211f5b0f23d",
   "metadata": {},
   "source": [
    "# @part2: Grammer Check 모델 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce755b06-1c22-46c4-8a20-cece5f1fa62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 13:46:28.252905: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-20 13:46:28.275476: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-20 13:46:28.307236: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-20 13:46:28.307267: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-20 13:46:28.307292: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-20 13:46:28.317277: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-20 13:46:28.317659: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-20 13:46:28.876163: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx, openvino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Framework not specified. Using pt to export to ONNX.\n",
      "Some weights of the model checkpoint at textattack/roberta-base-CoLA were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "Using framework PyTorch: 2.1.0+cpu\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "Compiling the model to AUTO ...\n",
      "Framework not specified. Using pt to export to ONNX.\n",
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "Using framework PyTorch: 2.1.0+cpu\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "Using framework PyTorch: 2.1.0+cpu\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> True\n",
      "/home/hong/openvino/.openvino_env/lib/python3.10/site-packages/transformers/modeling_utils.py:873: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if causal_mask.shape[1] < attention_mask.shape[1]:\n",
      "Using framework PyTorch: 2.1.0+cpu\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> True\n",
      "/home/hong/openvino/.openvino_env/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:508: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  elif past_key_value.shape[2] != key_value_states.shape[1]:\n",
      "Compiling the encoder to AUTO ...\n",
      "Compiling the decoder to AUTO ...\n",
      "Compiling the decoder to AUTO ...\n"
     ]
    }
   ],
   "source": [
    "## 모듈 임포트\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from optimum.intel.openvino import OVModelForSeq2SeqLM, OVModelForSequenceClassification\n",
    "import re\n",
    "import transformers\n",
    "\n",
    "\n",
    "grammar_checker_model_id = \"textattack/roberta-base-CoLA\"\n",
    "grammar_checker_dir = Path(\"model/roberta-base-cola\")\n",
    "grammar_checker_tokenizer = AutoTokenizer.from_pretrained(grammar_checker_model_id)\n",
    "\n",
    "if grammar_checker_dir.exists():\n",
    "    grammar_checker_model = OVModelForSequenceClassification.from_pretrained(grammar_checker_dir, device='AUTO')\n",
    "else:\n",
    "    grammar_checker_model = OVModelForSequenceClassification.from_pretrained(grammar_checker_model_id, export=True, device='AUTO')\n",
    "    grammar_checker_model.save_pretrained(grammar_checker_dir)\n",
    "\n",
    "grammar_checker_pipe = pipeline(\"text-classification\", model=grammar_checker_model, tokenizer=grammar_checker_tokenizer)\n",
    "\n",
    "\n",
    "grammar_corrector_model_id = \"pszemraj/flan-t5-large-grammar-synthesis\"\n",
    "grammar_corrector_dir = Path(\"model/flan-t5-large-grammar-synthesis\")\n",
    "grammar_corrector_tokenizer = AutoTokenizer.from_pretrained(grammar_corrector_model_id)\n",
    "\n",
    "if grammar_corrector_dir.exists():\n",
    "    grammar_corrector_model = OVModelForSeq2SeqLM.from_pretrained(grammar_corrector_dir, device='AUTO')\n",
    "else:\n",
    "    grammar_corrector_model = OVModelForSeq2SeqLM.from_pretrained(grammar_corrector_model_id, export=True, device='AUTO')\n",
    "    grammar_corrector_model.save_pretrained(grammar_corrector_dir)\n",
    "    \n",
    "grammar_corrector_pipe = pipeline(\"text2text-generation\", model=grammar_corrector_model, tokenizer=grammar_corrector_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363cac9b-d006-4aa6-9b67-f6dcf58c8a91",
   "metadata": {},
   "source": [
    "# @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986c88eb-6d12-45fa-bee4-0bbe749dcd42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae8f23-3188-485f-ab24-cf35dd5199cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a183dce0-7d2f-4dfa-9531-aa3b90309a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
